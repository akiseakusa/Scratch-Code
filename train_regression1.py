# -*- coding: utf-8 -*-
"""train_regression1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tGx_dkoYuNdBuL6q1CEm3OXdWNEcRt2L
"""

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import joblib
import matplotlib.pyplot as plt

class LinearRegression:
    def __init__(self, batch_size=32, regularization=0, max_epochs=100, patience=3):

        self.batch_size = batch_size
        self.regularization = regularization
        self.max_epochs = max_epochs
        self.patience = patience
        self.weights = None
        self.bias = None

    def fit(self, X, y, batch_size=32, regularization=0, max_epochs=100, patience=3, penalty = 200):

        self.batch_size = batch_size
        self.regularization = regularization
        self.max_epochs = max_epochs
        self.patience = patience


        # TODO: Initialize the weights and bias based on the shape of X and y.
        # print(X.shape)
        entries , features = X.shape
        self.weights = np.random.rand(features)
        self.bias = 0

        learning_rate = 0.01

        # Dividing validation test & training data
        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size= 0.1)

        # TODO: Implement the training loop.
        if entries < batch_size:
          batch_size = entries

        cost_list = []

        for i in range(max_epochs):

          #  The number of epochs to wait before stopping if the validation loss does not improve.
          n = len(cost_list)
          flag = 0
          if n - patience -1 >= 0 :
            for k in range(n-patience-1 , n-1 , 1):
              if cost_list[k] < cost_list[k+1]:
                flag += 1
          if flag == patience :
            i=max_epochs
            continue
          for j in range(0 , entries , batch_size):
            X_temp = X_train[j:j+batch_size]
            y_temp = y_train[j:j+batch_size]

            y_pred = np.dot(self.weights , X_temp.T)
            if len(X_temp)==0 :
              i=max_epochs
              continue

            if regularization == 0:
              diff_weights = -(2/len(X_temp))*(X_temp.T.dot(y_pred-y_temp))


            if regularization == 1:
              for k in range(len(self.weights)):
                if self.weights[k] > 0 :
                    diff_weights = -(2/len(X_temp))*(X_temp.T.dot(y_pred-y_temp))+penalty
                else :
                    diff_weights = -(2/len(X_temp))*(X_temp.T.dot(y_pred-y_temp))-penalty

            if regularization == 2:
                 diff_weights = -(2/len(X_temp))*(X_temp.T.dot(y_pred-y_temp))+(2*penalty*self.weights)


            diff_bias = -(2/len(X_temp))*np.sum(y_pred-y_temp)
            self.weights = self.weights - learning_rate * diff_weights
            self.bias = self.bias - learning_rate * diff_bias

            cost_list.append(self.score(X_temp,y_pred))

        return self.weights , self.bias , cost_list

    def predict(self, X):

        # TODO: Implement the prediction function.
        return np.dot(X, self.weights) + self.bias

    def r2_score(self,y, y_pred):
        corr_matrix = np.corrcoef(y, y_pred)
        corr = corr_matrix[0, 1]
        return corr ** 2

    def score(self, X, y):

        # TODO: Implement the scoring function.
        y_pred = self.predict(X)
        mean_squared_error = np.mean(np.square(y_pred - y))
        return mean_squared_error

# Load Iris Data
iris = load_iris()
iris_df = pd.DataFrame(data= iris.data, columns= iris.feature_names)
target_df = pd.DataFrame(data= iris.target, columns= ['species'])

#==========Model_1=====================

X1= iris_df.drop(labels= 'sepal length (cm)', axis= 1)
y1= iris_df['sepal length (cm)']

#  Splitting the data
X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size= 0.1)


print("Model 1 : To find sepal length (cm) ")
#  Object Creation
model=LinearRegression()

# Saving the Model
joblib.dump(model,'model_sepal_length')
#loading the Model
sepal_length = joblib.load('model_sepal_length')
w1,b1,error_list1 = sepal_length.fit(X1_train,y1_train,32,2,10)
y_pred=sepal_length.predict(X1_test)
print(w1,b1,error_list1)

sepal_length.score(X1_test,y1_test)

sepal_length.predict(X1_test)

accuracy = sepal_length.r2_score(y1_test,y_pred)
print(accuracy)